{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c048c9-d92b-45d9-a1eb-09ce9a4061ef",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a836eb-9922-4522-8ce5-62be7cb2f353",
   "metadata": {},
   "source": [
    "**Sources**: <br>\n",
    "[Angelopoulos, A. N., & Bates, S. (2021). A gentle introduction to conformal prediction and distribution-free uncertainty quantification. arXiv preprint arXiv:2107.07511](https://arxiv.org/abs/2107.07511)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740fc380-dd13-469b-86b1-e170cd0ae39f",
   "metadata": {},
   "source": [
    "## Conformal Prediction Part 1: Basic Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5de783-5bb0-40b7-b387-ae2f42d6e526",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## General Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d58c0-ad0d-4c1a-932b-3b870d578c28",
   "metadata": {},
   "source": [
    "**Conformal Prediction** \n",
    "\n",
    "Conformal Prediction can be used with any pre-trained model, such as a neural network. It aims to predict an interval of target value instead of a point-wise prediction.It works perfectly well with the concept of **uncertainty**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c27de-d62d-45f2-9801-59e65c6c7ac3",
   "metadata": {},
   "source": [
    "*What we need*:\n",
    "- A *Dataset* : $\\{x_i,y_i\\}^n_{i=1}$, which is independent and identically distributed (i.i.d).\n",
    "- A *Model* : $\\hat{\\pi}_y(x)$, $\\pi_y(x) = \\mathbb{P}[Y=y | X=x]$\n",
    "- A *New Sample* : $X_{n+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342e23c-0cd3-4c09-9673-9a95885b8a81",
   "metadata": {},
   "source": [
    "*What we generate*:\n",
    "- A Set of prediction $T(x_{n+1})  \\subseteq y$, which contains the true class $y_{n+1}$ with high $\\mathbb{P}$ (probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a9cbc-bdd2-471e-990b-94a8ec130777",
   "metadata": {},
   "source": [
    "**Coverage**\n",
    "\n",
    "Coverage means that $\\mathbb{P}[y_{n+1} \\in T(x_{n+1})] \\geq 1-\\alpha$. The probability of the label is in the prediction set generated by the the new sample $x_{n+1}$ is greater than $1-\\alpha$, where $\\alpha$ is a hyper-parameter error rate.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542fae1e-11b3-43bf-aca9-20fc2ac98d9c",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "- Exact Coverage: $|T(x_{n+1})| = 1$\n",
    "- Small Set: $|T(x_{n+1})| < n$\n",
    "- \"Adaptive\": $|T(x_{n+1})|$ smaller for easy task and $|T(x_{n+1})| is bigger for hard task$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828df008-3b89-4a76-be7f-779b5ce0ed37",
   "metadata": {},
   "source": [
    "**Property**\n",
    "- Any Model\n",
    "- Any Dataset\n",
    "- Score Function Matters (Important Decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ebe61-d8a0-4eb7-b72c-f4d88efc35a7",
   "metadata": {},
   "source": [
    "**Conformal Prediction (General Case)**\n",
    "1) Identify a heuristic notion of uncertainty\n",
    "2) Define a scalar score function $s(x,y) \\in R$\n",
    "3) Compute $\\hat{q} = \\frac{\\lceil (n+1)(1-\\alpha)\\rceil}{n}$ is the quantile of $s(x_1,y_1),\\cdots, s(x_n),y_n$ (ca)\n",
    "4) Deploy: $T(x) = \\{y: s(x,y) \\leq \\hat{q}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bc266-098f-429b-8d80-181efb255929",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Theorem 1 [Coverage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b764f32-88a3-4dbe-bb5b-13287d459aed",
   "metadata": {},
   "source": [
    "$1-\\alpha \\leq \\mathbb{P}[y_{n+1} \\in T(x_{n+1})] \\leq 1-\\alpha +\\frac{1}{n+1}$\n",
    "\n",
    "This can be applied to any algorithm, any dataset.\n",
    "\n",
    "\n",
    "*Why it works?*  \n",
    "\n",
    "Symmetry!!! The probability of x3 falls on the left of  q is greater than $1-\\alpha$\n",
    "\n",
    "---x2-------------x1----------q--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd28316-6858-4320-b8dc-02786cdee2b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Methods 1 (Vovk et al)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc21fe-0bdb-4940-85b0-dc8cfa3ca59e",
   "metadata": {},
   "source": [
    "What if we learn a rule to predict sets? using calbration dataset $\\{x_i,y_i\\}^{n}_{i=1}$\n",
    "\n",
    "1. Get estimated score of the correct classes ($y_i$) for each of $(x_i,y_i)$: $\\{E_{i}\\}^{n}_{i=1}$\n",
    "2. Take the 10% quantile: $\\hat{q}$ - At least 90% of examples have true class score above $\\hat{q}$\n",
    "```\n",
    "q_hat = np.quantile([E1,...En],0.1,'lower')\n",
    "```\n",
    "\n",
    "3. Form prediction sets: {All classes whose score exceeds $\\hat{q}$ when $x_{n+1}$ input} = Valid Prediction Set! $T(x_{n+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d374c-984c-4ee6-b468-4f38ca13d67f",
   "metadata": {},
   "source": [
    "## Method 2 (Romano et al)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0856693-0481-437a-82b9-2849a90304f3",
   "metadata": {},
   "source": [
    "|       Method 1       |   Method 2|\n",
    "|----------------------|-----------|\n",
    "|smallest average size | usually larger size|\n",
    "| not very adaptive | designed to be adaptive|\n",
    "|only use output of true class | use output of all classes|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c24ce9-f300-4917-bd16-3c350f31dd51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Conformalized Quantile **(Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4327859-71dc-4677-b319-587320be53ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1) Get a score of the correct class\n",
    "> Sort the softmax estimation. $E_i = \\sum_{j=1}^k \\hat{\\pi}(x_i)_{(j)}$ where k is the rank of true class. Sum up all scores from high to low until the score of the true label is included.\n",
    "\n",
    "2) Take the 90% quantile\n",
    ">```q_hat = np.quantile([E1,...En],0.9,'upper')```\n",
    "\n",
    "3) Form prediction sets:\n",
    "> {The K most likely classes where $\\sum_{j=1}^K \\hat{\\pi}(x_{n+1})_{y_{n+1}} \\geq \\hat{q}$ = Valid Prediction Set $T(x_{n+1})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d2e50-5349-4501-b10e-51ed8f472a25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Conformalized Quantile **(Regression)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "762da5a8-1095-4340-abcd-7ee867281f9b",
   "metadata": {},
   "source": [
    "We have two models $\\hat{t}_{\\alpha/2}(x)$ and$\\hat{t}_{1-\\alpha/2}(x)$, which is 5% quantile and 95% quantile. This can be achieved by training NN with [pinball loss](https://www.lokad.com/pinball-loss-function-definition/).\n",
    "\n",
    "> *pinball* loss, also referred to as the quantile loss, can be used to assess the accuracy of a quantile forecast.\n",
    "> \n",
    "> $\\begin{align}L_{\\tau}(y,z) & = (y-z)\\tau & \\text{ if } y\\geq z\\\\\n",
    "        &= (z-y)(1-\\tau) & \\text{ if } z > y\n",
    "        \\end{align} $\n",
    "> \n",
    "> where $\\tau$ is the target quantile, $y$ is the real value and $z$ is the quamtile forecast\n",
    ">\n",
    "> The pinball loss is always positive. The larger the value of *pinball* loss, the further away from the target $y$. The lower the pinball loss, the more accurate the quantile forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94ee5f-62d1-43cc-b7fd-278ebe400a21",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "  <img height=\"100%\" width=\"50%\" src=\"sources/conformalized_quantile_regression.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0cdc79-07f9-4d40-a709-f75be4214ab2",
   "metadata": {},
   "source": [
    "1) Get score of correct class\n",
    "> $E_i$ = Projection of $y_i$ onto $[\\hat{t}_{\\alpha/2}(x_i),\\hat{t}_{1-\\alpha/2}(x_i)]$, or distance of how far the estimation is outside of the band.\n",
    "\n",
    "2) Take the 90% quantile\n",
    ">```q_hat = np.quantile([E1,...En],0.9,'upper')```\n",
    "\n",
    "3) Form prediction sets\n",
    ">$T(x_{n+1})$ = Valid Prediction Set $T(x_{n+1}) = [\\hat{t}_{\\alpha/2}(x_{n+1})-\\hat{q},\\hat{t}_{1-\\alpha/2}(x_{n+1})+\\hat{q}]$ = Valid Prediction Set! $T(x_{n+1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a2dda-3e8a-4337-a94c-c784c7773530",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Conformal Prediction Part 2: Conditional Coverage and Diagnostics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
