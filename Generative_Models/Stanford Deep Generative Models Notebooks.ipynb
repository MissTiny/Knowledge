{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ab300e-e58a-4fc8-9c64-d65beb99c52d",
   "metadata": {},
   "source": [
    "# Deep Generative Model\n",
    "This is a study note for Stanford CS236 Deep Generative Model.\n",
    "Additional Resources:\n",
    "[Course Github Notes](https://deepgenerativemodels.github.io/notes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308b170-4220-4cf6-bab2-08a2ea21c843",
   "metadata": {},
   "source": [
    "## Module 1: Introduction to Generative Models\n",
    "- Suggest Readings:\n",
    "    - [Deep Generative Models](https://ermongroup.github.io/generative-models/)\n",
    "    - [Generative Modeling by Estimating Gradients of the Data Distribution](https://yang-song.net/blog/2021/score/)\n",
    "    - [Tutorial on Deep Generative Models](https://www.youtube.com/watch?v=JrO5fSskISY)\n",
    "    - [Learning Deep Generative Models](https://www.cs.cmu.edu/~rsalakhu/papers/annrev.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802ea3a-8704-443f-9a9b-00e25a53c120",
   "metadata": {},
   "source": [
    "### What is Generative Modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b95b5-03bd-44e7-97dc-773a613b7d33",
   "metadata": {},
   "source": [
    "**Generative Models** contains two parts:\n",
    "- **Generation (graphics)**: From high level description to raw sensory outputs \n",
    "- **Inference (vision as inverse graphics)**: From Raw sensory outputs to high level descriptions.\n",
    "\n",
    "**Statistical** Generative Models are **learned from data**.\n",
    "This course depends less on prior data but computer graphics deeps on more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f35f8-4978-43c4-bb90-f247045ebf23",
   "metadata": {},
   "source": [
    "#### Statistical Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52c910-ba2f-47eb-b1fa-4a10c8f51ad0",
   "metadata": {},
   "source": [
    "\n",
    "A **statistical generative** model is a probability distribution p(x):\n",
    "- **Data**: Samples\n",
    "- **Prior Knowledge**: parametric form, loss function, optimization algorithm\n",
    "\n",
    "Image x $\\rightarrow$ A probability distribution p(x) $\\rightarrow$ scalar probability p(x)\n",
    "\n",
    "It is generative because sampling from p(x) generates new images.\n",
    "\n",
    "It can be used to build a simulator for the data-generating process.\n",
    "\n",
    "Control Signals/Potential datapoints $\\rightarrow$ Data Simulator = Statistical Model = Generative Model $\\rightarrow$ New datapoints/Probability values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf514e95-ca16-47f7-b87b-248113dce09e",
   "metadata": {},
   "source": [
    "### Audio and Image Applications of Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c1b1c-5ddf-426c-8a17-11b109e62df2",
   "metadata": {},
   "source": [
    "- Data Generation in the real world\n",
    "    - Text to Image: [Language-guided artwork creation](https://chainbreakers.kath.io/)\n",
    "    - Draw Image to Realistic Images[Meng, He, Song et al ICLR 2022](https://arxiv.org/abs/2108.01073)\n",
    "- Solving inverse problems with generative models\n",
    "    - Medical image reconstruction [Song et al ICLR 2022](https://arxiv.org/abs/2111.08005)\n",
    "- Outlier Detection with genertive models\n",
    "    - Outlier Detection [Song et al ICLR 2018](https://arxiv.org/abs/1710.10766)\n",
    "- Progress in Generative Models of Images\n",
    "    - GANs [Ian Goodfellow 2019](https://arxiv.org/abs/1406.2661)\n",
    "    - Diffusion Models [Song et al 2021](https://arxiv.org/abs/2101.09258)\n",
    "        - Text2Image Diffusion Models\n",
    "- Progress in Inverse Problems\n",
    "    -  Low Resolution $\\rightarrow$ High resolution [Menon et al, 2020](https://arxiv.org/abs/2003.03808)\n",
    "    -  Mask $\\rightarrow$ Full Image [Liu et al 2018](https://arxiv.org/abs/1804.07723)\n",
    "    -  Greyscale Images $\\rightarrow$  Color Image\n",
    "    -  Scatch $\\rightarrow$ Fine Image\n",
    "    -  Origin Images $\\rightarrow$ Edited Images\n",
    "-  Audio\n",
    "    - WaveNet[van den Oord et al 2016c](https://arxiv.org/abs/1609.03499)\n",
    "    - Diffusion Text2Speech [Betker, Better Speech Synthesis through scaling 2023](https://arxiv.org/abs/2305.07243)\n",
    "    - Conditional Generative Model: Low-Resolution Audio Signal $\\rightarrow$ High-Resolution Audio Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af7571-94e6-4d2f-9963-28702c2f5802",
   "metadata": {},
   "source": [
    "### Language, Video, and Robotic Applications of Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd890d-1ff2-46bb-a5c7-85c283bf8ba7",
   "metadata": {},
   "source": [
    "- Language Generation [Radford et al 2019](https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf)\n",
    "    - Conditional Generative Model *P(next word | previous word)*\n",
    "    - ChatGPT\n",
    "- Machine Translation\n",
    "    - Conditional Generative Model *P(English Text | Chinese Text)*\n",
    "- Code Generation\n",
    "- Video Generation\n",
    "- Imitation Learning\n",
    "    - Conditional Generative Model *P(actions | past observations)* [Li et al 2017](https://arxiv.org/abs/1701.01036) | [Janner et al 2022](https://arxiv.org/abs/2205.09991)\n",
    "- Molecule Generation\n",
    "- DeepFake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19860f-56e0-45e2-929f-d6e6b371789a",
   "metadata": {},
   "source": [
    "### Roadmap and Challenges in Generative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e77e9-a003-41c6-b619-c373093d4e6e",
   "metadata": {},
   "source": [
    "**Representation**: how do we model the joint distribution of many random variables?\n",
    "\n",
    "**Learning** What is the right way to compare probability distributions?\n",
    "\n",
    "**Inference** How do we invert the generation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e91e2-8611-431d-b760-13d48329b93e",
   "metadata": {},
   "source": [
    "### Generative Model Curse of Dimensionality and Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129020d4-d2da-4742-a2e1-b8ccd4c92463",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed7405-3224-46b7-968a-3b738bdd32a5",
   "metadata": {},
   "source": [
    "- What is a generative model\n",
    "- Representing probability distributions\n",
    "    - Curse of dimensionality\n",
    "    - Crash course on graphical models (Bayesian networks)\n",
    "    - Generative vs discriminative models\n",
    "    - Neural models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb3885-8aa5-4668-ac74-40ed41ac9004",
   "metadata": {},
   "source": [
    "#### Learning  a generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a15b9-863e-450e-994c-36df1af788d0",
   "metadata": {},
   "source": [
    "We want to learn a probability distribution $p(x)$ over images x such that\n",
    "\n",
    "**Generation** If we sample $x_{new} \\sim p(x)$,$x_{new}$ should look like a dog (sampling)\n",
    "\n",
    "**Density Estimation** p(x) should be high if x looks like a dog and low otherwise (anomly detection)\n",
    "\n",
    "**Unsupervised Representation Learning**: We should be able to learn what these images have in common, e.g. ears, tail, etc(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc30ac-de0c-457f-9187-3c3e66aea55e",
   "metadata": {},
   "source": [
    "#### How to Represent $p(x)$                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cf144-313c-492c-9462-aa56469e8796",
   "metadata": {},
   "source": [
    "**Basic Discrete Distribution**\n",
    "- Bernoulli Distribution: (biased) coin flip\n",
    "    - $D = {Head,Tails}$\n",
    "    - $P(X=Heads) = p, P(X=Tails) = 1-p$\n",
    "    - $X \\sim Ber(p)$\n",
    "- Categorical Distribution: (biased) m-sided dice\n",
    "    - $D={1,...,m}$\n",
    "    - $P(Y=i) = p, \\sum p_i=1$\n",
    "    - $Y \\sim Cat(p_1,...,p_m)$\n",
    "\n",
    "Example of joint distribution: \n",
    "- Modeling pixels - Red, Blue, Green: $Val(R) = Val(B) = Val(G) = {0,...,255} = 256 * 256 * 256 - 1$ Number of parameters.\n",
    "- Modeling grey image numbers: Bernoulli $Val(X_i)={0,1} = 2^n -1 $ Number of parameters.\n",
    "\n",
    "$x-1$ number of parameters because the sum of $x$ parameters needs to sum up to 1; therefore, the last one is determined based on the previous $x-1$ parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b65766-81df-496b-88ed-a6b6a5e21864",
   "metadata": {},
   "source": [
    "**Assumption**: Independent\n",
    "$$p(x_1,...,x_n) = p(x_1)p(x_2)...p(x_n) $$\n",
    "\n",
    "- $2^n$ possible states\n",
    "- $p(x_1,...,x_n)$ we need only 1 parameters to specify marginal distribution $p(x_1)$\n",
    "- $2^n$ entries can be described by just n numbers (if $|Val(X_i)| = 2).\n",
    "\n",
    "Problems: Too strong. Model may not be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa631a-2f7b-4cd8-853d-f9a610ae57bd",
   "metadata": {},
   "source": [
    "**Two Important Rules**\n",
    "- Chain Rule\n",
    "    - $P(S_1 \\cap S_2 \\cap \\cdots \\cap S_n) = p(S_1)p(S_2 | S_1) \\cdots p(S_n | S_1 \\cap \\cdots \\cap S_{n-1})$\n",
    "- Bayes' Rule\n",
    "    - $p(S_1 | S_2) = \\frac{p(S_1 \\cap S_2)}{p(S_2)} = \\frac{p(S_2 | S_1)p(S_1)}{p(S_2)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f2c00-f3ca-4f1e-9f22-a08bdc4d2adf",
   "metadata": {},
   "source": [
    "**Structure Through Conditional Independence**\n",
    "$$p(x_1,...,x_n) = p(x_1)p(x_2 |x_1)p(x_3 | x_1,x_2) \\cdots p(x_n | x_1,...,x_{n-1})$$\n",
    "\n",
    "- $p(x_1)$ requires 1 parameters.\n",
    "- $p(x_2 | x_1 = 0)$ requires 1 parameter, $p(x_2 | x_1 = 1)$ requires 1 parameter\n",
    "- In total, we need $1+2+ ... +2^{n-1}= 2^n-1$ parameters\n",
    "- It is still exponential.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e6e14-01ee-4996-a1d3-1e410b65302d",
   "metadata": {},
   "source": [
    "Now let's try, such as predicting next word.\n",
    "$$\\begin{align}\n",
    "p(x_1,...,x_n) & = p(x_1)p(x_2 |x_1)p(x_3 | x_1,x_2) \\cdots p(x_n | x_1,\\cdots,x_{n-1}) \\\\\n",
    "& = p(x_1) p(x_2 |x_1)p(x_3 | x_2)\\cdots p(x_n | x_{n-1})\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "It requires $2n-1$ parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313d571-30f6-488e-b1b1-3b83de0e5ecf",
   "metadata": {},
   "source": [
    "**Bayes Network** General Idea\n",
    "\n",
    "- Use conditional parameterization (instead of joint parameterization)\n",
    "- For each random variable $X_i$ specify $p(x_i |  \\mathbf{x_{A_i}})$ for set $\\mathbf{X_{A_i}}$ of random variables.\n",
    "\n",
    "$$p(x_1,\\cdots,x_n) = \\prod_i p(x_i |\\mathbf{x_{A_i}})$$\n",
    "\n",
    "- We need to guarantee it is a legal probability distribution.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a240a78-4e95-406c-830a-6efb7b6b4bac",
   "metadata": {},
   "source": [
    "**Bayesian Network** Formal\n",
    "\n",
    "A **Bayesian Network** is specified by a *directed* **acyclic** graph (DAG), G=(V,E), with\n",
    "- One node $i \\in V$ for each random variable $X_i$\n",
    "- One conditional probability distribution (CPD) per node, $p(x_i |\\mathbf{x_{Pa_i}} ), specifying the variable's probability conditioned on its parents' value.\n",
    "\n",
    "Graph $G=(V,E)$ is called the structure of the Bayesian Network\n",
    "\n",
    "Defines a joint distribution:\n",
    "$$p(x_1,\\cdots,x_n) = \\prod_i p(x_i |\\mathbf{x_{{Pa_i}})$$\n",
    "\n",
    "Claim: $p(x_1,...,x_n)$ is valid probability distribution because of ordering implied by DAG.\n",
    "**Economical Representation**: Exponential in $|Pa(i)|$, not |V|$$p(x_1,\\cdots,x_n) = \\prod_i p(x_i |\\mathbf{x_{A_i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c894b-de91-4100-b711-ee84fe3e6b53",
   "metadata": {},
   "source": [
    "### Generative vs Discriminative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2e18d-f997-4766-b7f3-71728fce601a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
