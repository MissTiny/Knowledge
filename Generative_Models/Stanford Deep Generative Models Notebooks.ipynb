{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ab300e-e58a-4fc8-9c64-d65beb99c52d",
   "metadata": {},
   "source": [
    "# Deep Generative Model\n",
    "This is a study note for Stanford CS236 Deep Generative Model.\n",
    "Additional Resources:\n",
    "[Course Github Notes](https://deepgenerativemodels.github.io/notes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308b170-4220-4cf6-bab2-08a2ea21c843",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Module 1: Introduction to Generative Models\n",
    "- Suggest Readings:\n",
    "    - [Deep Generative Models](https://ermongroup.github.io/generative-models/)\n",
    "    - [Generative Modeling by Estimating Gradients of the Data Distribution](https://yang-song.net/blog/2021/score/)\n",
    "    - [Tutorial on Deep Generative Models](https://www.youtube.com/watch?v=JrO5fSskISY)\n",
    "    - [Learning Deep Generative Models](https://www.cs.cmu.edu/~rsalakhu/papers/annrev.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802ea3a-8704-443f-9a9b-00e25a53c120",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### What is Generative Modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b95b5-03bd-44e7-97dc-773a613b7d33",
   "metadata": {},
   "source": [
    "**Generative Models** contains two parts:\n",
    "- **Generation (graphics)**: From high level description to raw sensory outputs \n",
    "- **Inference (vision as inverse graphics)**: From Raw sensory outputs to high level descriptions.\n",
    "\n",
    "**Statistical** Generative Models are **learned from data**.\n",
    "This course depends less on prior data but computer graphics deeps on more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f35f8-4978-43c4-bb90-f247045ebf23",
   "metadata": {},
   "source": [
    "#### Statistical Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52c910-ba2f-47eb-b1fa-4a10c8f51ad0",
   "metadata": {},
   "source": [
    "\n",
    "A **statistical generative** model is a probability distribution $p(x)$:\n",
    "- **Data**: Samples\n",
    "- **Prior Knowledge**: parametric form, loss function, optimization algorithm\n",
    "\n",
    "Image $x$ $\\rightarrow$ A probability distribution $p(x)$ $\\rightarrow$ scalar probability $p(x)$.\n",
    "\n",
    "It is generative because sampling from $p(x)$ generates new images.\n",
    "\n",
    "It can be used to build a simulator for the data-generating process.\n",
    "\n",
    "Control Signals/Potential datapoints $\\rightarrow$ Data Simulator = Statistical Model = Generative Model $\\rightarrow$ New datapoints/Probability values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf514e95-ca16-47f7-b87b-248113dce09e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Audio and Image Applications of Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c1b1c-5ddf-426c-8a17-11b109e62df2",
   "metadata": {},
   "source": [
    "- Data Generation in the real world\n",
    "    - Text to Image: [Language-guided artwork creation](https://chainbreakers.kath.io/)\n",
    "    - Draw Image to Realistic Images[Meng, He, Song et al ICLR 2022](https://arxiv.org/abs/2108.01073)\n",
    "- Solving inverse problems with generative models\n",
    "    - Medical image reconstruction [Song et al ICLR 2022](https://arxiv.org/abs/2111.08005)\n",
    "- Outlier Detection with genertive models\n",
    "    - Outlier Detection [Song et al ICLR 2018](https://arxiv.org/abs/1710.10766)\n",
    "- Progress in Generative Models of Images\n",
    "    - GANs [Ian Goodfellow 2019](https://arxiv.org/abs/1406.2661)\n",
    "    - Diffusion Models [Song et al 2021](https://arxiv.org/abs/2101.09258)\n",
    "        - Text2Image Diffusion Models\n",
    "- Progress in Inverse Problems\n",
    "    -  Low Resolution $\\rightarrow$ High resolution [Menon et al, 2020](https://arxiv.org/abs/2003.03808)\n",
    "    -  Mask $\\rightarrow$ Full Image [Liu et al 2018](https://arxiv.org/abs/1804.07723)\n",
    "    -  Greyscale Images $\\rightarrow$  Color Image\n",
    "    -  Scatch $\\rightarrow$ Fine Image\n",
    "    -  Origin Images $\\rightarrow$ Edited Images\n",
    "-  Audio\n",
    "    - WaveNet[van den Oord et al 2016c](https://arxiv.org/abs/1609.03499)\n",
    "    - Diffusion Text2Speech [Betker, Better Speech Synthesis through scaling 2023](https://arxiv.org/abs/2305.07243)\n",
    "    - Conditional Generative Model: Low-Resolution Audio Signal $\\rightarrow$ High-Resolution Audio Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af7571-94e6-4d2f-9963-28702c2f5802",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Language, Video, and Robotic Applications of Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd890d-1ff2-46bb-a5c7-85c283bf8ba7",
   "metadata": {},
   "source": [
    "- Language Generation [Radford et al 2019](https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf)\n",
    "    - Conditional Generative Model *P(next word | previous word)*\n",
    "    - ChatGPT\n",
    "- Machine Translation\n",
    "    - Conditional Generative Model *P(English Text | Chinese Text)*\n",
    "- Code Generation\n",
    "- Video Generation\n",
    "- Imitation Learning\n",
    "    - Conditional Generative Model *P(actions | past observations)* [Li et al 2017](https://arxiv.org/abs/1701.01036) | [Janner et al 2022](https://arxiv.org/abs/2205.09991)\n",
    "- Molecule Generation\n",
    "- DeepFake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19860f-56e0-45e2-929f-d6e6b371789a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Roadmap and Challenges in Generative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e77e9-a003-41c6-b619-c373093d4e6e",
   "metadata": {},
   "source": [
    "**Representation**: how do we model the joint distribution of many random variables?\n",
    "\n",
    "**Learning** What is the right way to compare probability distributions?\n",
    "\n",
    "**Inference** How do we invert the generation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e91e2-8611-431d-b760-13d48329b93e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generative Model Curse of Dimensionality and Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129020d4-d2da-4742-a2e1-b8ccd4c92463",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed7405-3224-46b7-968a-3b738bdd32a5",
   "metadata": {},
   "source": [
    "- What is a generative model\n",
    "- Representing probability distributions\n",
    "    - Curse of dimensionality\n",
    "    - Crash course on graphical models (Bayesian networks)\n",
    "    - Generative vs discriminative models\n",
    "    - Neural models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb3885-8aa5-4668-ac74-40ed41ac9004",
   "metadata": {},
   "source": [
    "#### Learning  a generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a15b9-863e-450e-994c-36df1af788d0",
   "metadata": {},
   "source": [
    "We want to learn a probability distribution $p(x)$ over images x such that\n",
    "\n",
    "**Generation** If we sample $x_{new} \\sim p(x)$,$x_{new}$ should look like a dog (sampling)\n",
    "\n",
    "**Density Estimation** p(x) should be high if x looks like a dog and low otherwise (anomly detection)\n",
    "\n",
    "**Unsupervised Representation Learning**: We should be able to learn what these images have in common, e.g. ears, tail, etc(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc30ac-de0c-457f-9187-3c3e66aea55e",
   "metadata": {},
   "source": [
    "#### How to Represent $p(x)$                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cf144-313c-492c-9462-aa56469e8796",
   "metadata": {},
   "source": [
    "**Basic Discrete Distribution**\n",
    "- Bernoulli Distribution: (biased) coin flip\n",
    "    - $D = {Head,Tails}$\n",
    "    - $P(X=Heads) = p, P(X=Tails) = 1-p$\n",
    "    - $X \\sim Ber(p)$\n",
    "- Categorical Distribution: (biased) m-sided dice\n",
    "    - $D={1,...,m}$\n",
    "    - $P(Y=i) = p, \\sum p_i=1$\n",
    "    - $Y \\sim Cat(p_1,...,p_m)$\n",
    "\n",
    "Example of joint distribution: \n",
    "- Modeling pixels - Red, Blue, Green: $Val(R) = Val(B) = Val(G) = {0,...,255} = 256 * 256 * 256 - 1$ Number of parameters.\n",
    "- Modeling grey image numbers: Bernoulli $Val(X_i)={0,1} = 2^n -1 $ Number of parameters.\n",
    "\n",
    "$x-1$ number of parameters because the sum of $x$ parameters needs to sum up to 1; therefore, the last one is determined based on the previous $x-1$ parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b65766-81df-496b-88ed-a6b6a5e21864",
   "metadata": {},
   "source": [
    "**Assumption**: Independent\n",
    "$$p(x_1,...,x_n) = p(x_1)p(x_2)...p(x_n) $$\n",
    "\n",
    "- $2^n$ possible states\n",
    "- $p(x_1,...,x_n)$ we need only 1 parameters to specify marginal distribution $p(x_1)$\n",
    "- $2^n$ entries can be described by just n numbers (if $|Val(X_i)| = 2$).\n",
    "\n",
    "Problems: Too strong. Model may not be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa631a-2f7b-4cd8-853d-f9a610ae57bd",
   "metadata": {},
   "source": [
    "**Two Important Rules**\n",
    "- Chain Rule\n",
    "    - $P(S_1 \\cap S_2 \\cap \\cdots \\cap S_n) = p(S_1)p(S_2 | S_1) \\cdots p(S_n | S_1 \\cap \\cdots \\cap S_{n-1})$\n",
    "- Bayes' Rule\n",
    "    - $p(S_1 | S_2) = \\frac{p(S_1 \\cap S_2)}{p(S_2)} = \\frac{p(S_2 | S_1)p(S_1)}{p(S_2)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f2c00-f3ca-4f1e-9f22-a08bdc4d2adf",
   "metadata": {},
   "source": [
    "**Structure Through Conditional Independence**\n",
    "$$p(x_1,...,x_n) = p(x_1)p(x_2 |x_1)p(x_3 | x_1,x_2) \\cdots p(x_n | x_1,...,x_{n-1})$$\n",
    "\n",
    "- $p(x_1)$ requires 1 parameters.\n",
    "- $p(x_2 | x_1 = 0)$ requires 1 parameter, $p(x_2 | x_1 = 1)$ requires 1 parameter\n",
    "- In total, we need $1+2+ ... +2^{n-1}= 2^n-1$ parameters\n",
    "- It is still exponential.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e6e14-01ee-4996-a1d3-1e410b65302d",
   "metadata": {},
   "source": [
    "Now let's try, such as predicting next word.\n",
    "$$\\begin{align}\n",
    "p(x_1,...,x_n) & = p(x_1)p(x_2 |x_1)p(x_3 | x_1,x_2) \\cdots p(x_n | x_1,\\cdots,x_{n-1}) \\\\\n",
    "& = p(x_1) p(x_2 |x_1)p(x_3 | x_2)\\cdots p(x_n | x_{n-1})\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "It requires $2n-1$ parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313d571-30f6-488e-b1b1-3b83de0e5ecf",
   "metadata": {},
   "source": [
    "**Bayes Network** General Idea\n",
    "\n",
    "- Use conditional parameterization (instead of joint parameterization)\n",
    "- For each random variable $X_i$ specify $p(x_i |  \\mathbf{x_{A_i}})$ for set $\\mathbf{X_{A_i}}$ of random variables.\n",
    "\n",
    "$$p(x_1,\\cdots,x_n) = \\prod_i p(x_i |\\mathbf{x_{A_i}})$$\n",
    "\n",
    "- We need to guarantee it is a legal probability distribution.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a240a78-4e95-406c-830a-6efb7b6b4bac",
   "metadata": {},
   "source": [
    "**Bayesian Network** Formal\n",
    "\n",
    "A **Bayesian Network** is specified by a *directed* **acyclic** graph (DAG), $G=(V,E)$, with\n",
    "- One node $i \\in V$ for each random variable $X_i$\n",
    "- One conditional probability distribution (CPD) per node, $p(x_i |\\mathbf{x_{Pa_i}})$, specifying the variable's probability conditioned on its parents' value.\n",
    "\n",
    "Graph $G=(V,E)$ is called the structure of the Bayesian Network\n",
    "\n",
    "Defines a joint distribution:\n",
    "$$p(x_1, \\cdots, x_n) = \\prod_i p(x_i |\\mathbf{x_{Pa_i}})$$\n",
    "\n",
    "**Claim**: $p(x_1,...,x_n)$ is valid probability distribution because of ordering implied by DAG.\n",
    "\n",
    "**Economical Representation**: Exponential in $|Pa(i)|$, not |V|.\n",
    "$$p(x_1,\\cdots,x_n) = \\prod_i p(x_i |\\mathbf{x_{A_i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c894b-de91-4100-b711-ee84fe3e6b53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generative v.s. Discriminative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc38397-fc2d-4523-929b-2ae585fee266",
   "metadata": {},
   "source": [
    "**Naive Bayes for Single Label Prediction**\n",
    "\n",
    "- Words are conditionally independent given Y\n",
    "    - Let $1:n$ index the words in our vocabulary\n",
    "    - $X_i = 1$ if word $i$ appears in an email, and 0 otherwise\n",
    "    - E-mails are drawn according to some distribution $p(Y,X_1,\\cdots,x_n)$\n",
    "\n",
    "Then,\n",
    "$$p(y,x_1,\\cdots,x_n) = p(y) \\prod_{i=1}^n p(x_i |y)$$\n",
    "\n",
    "**Estimate** parameters from training data. **Predict** with Bayes rule:\n",
    "$$p(Y=1 | x_1,\\cdots,x_n) = \\frac{p(Y=1)\\prod_{i=1}^n p(x_i | Y = 1)}{\\sum_{y=\\{0,1\\}} p(Y=y) \\prod_{i=1}^n p(x_i | Y=y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2e18d-f997-4766-b7f3-71728fce601a",
   "metadata": {},
   "source": [
    "Chain Rule $p(Y,\\mathbf{X}) = p(\\mathbf{X} | Y) p(Y) = p(Y|\\mathbf{X}) p(\\mathbf{X})$\n",
    "\n",
    "Corresponding Bayesian Networks:<br>\n",
    "*Generative* $Y \\rightarrow X$ <br>\n",
    "*Discriminative* $X \\rightarrow Y$ <br>\n",
    "\n",
    "Suppose all we need for prediction is $p(Y|\\mathbf{X})$\n",
    "\n",
    "In the left model, we need to specify both $p(Y)$ and $p(\\mathbf{X}|Y)$, then compute $p(Y | \\mathbf{X})$ via the Bayes rule.\n",
    "\n",
    "In the right model, it suffices to estimate just the **conditional distribution** $p(Y|\\mathbf{X})$ \n",
    "- We never need to model/learn/use $p(\\mathbf{X})$!\n",
    "- Called a **discriminative** model because it is only useful for discriminating Y's label when given $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b9e8d-f8d1-4ab5-adfe-a44a1148498a",
   "metadata": {},
   "source": [
    "$$p(Y,\\mathbf{X}) = p(Y)p(X_1| Y )p(X_2 | Y,X_1) \\cdots p(X_n | Y,X_1,\\cdots,X_{n-1})$$\n",
    "$$p(Y,\\mathbf{X}) = p(X_1)p(X_2| X_1 )p(X_3 | X_1,X_2) \\cdots p(Y | X_1,\\cdots,X_{n-1},X_n)$$\n",
    "- In the generative model, $p(Y)$ is simple, but how do we parameterize $p(X_i | \\mathbf{X}_{pa(i)}, Y)$\n",
    "- In the discriminative model, how do we parameterize $p(Y | \\mathbf{X})$? Here we assume we don't care about modeling $p(\\mathbf{X})$ because  $\\mathbf{X}$ is always given to us in a classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a079057-4853-428e-9d69-2eb9d9ec7a82",
   "metadata": {},
   "source": [
    "**Naive Bayes**\n",
    "- For the generative model, assume that $X_i \\perp X_{-i} | Y$ **Naive Bayes**\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "  <img height=\"100%\" width=\"50%\" src=\"sources/M1_1_6.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989442d-ee08-4223-8f0a-7d407980d2a5",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "Discriminative Model: $$p(Y=1|\\mathbf{x;\\alpha}) = f(\\mathbf{x},a)$$\n",
    "\n",
    "It is a parameterized function of x (regression). It has to be between 0 and 1.\n",
    "\n",
    "Linear Dependence: \n",
    "\n",
    "let $z(\\alpha;x)= \\alpha_0 + \\sum_{i=1}^n \\alpha_i x_i$. \n",
    "\n",
    "Then, $p(Y=1 | x;\\alpha) = \\sigma (z (\\alpha, x))$ where $\\sigma(z) = \\frac{1}{1+e^{-z}}$ is called **logistic function**.\n",
    "\n",
    "\n",
    "- Decision Boundary $p(Y=1 | x;\\alpha) > 0.5$ is linear in x\n",
    "- Equal Probability contours are straight lines.\n",
    "\n",
    "Logistic model does not assume $X_i \\perp X_{-i} | Y$. For example, in spam classification. Let $X_1$ = \"bank\" in email and $X_2$ = \"account\" in email. Assume that regardless of whether spam, these always appear together, i.e. $X_1 = X_2$.\n",
    "\n",
    "Learning in naive Bates results in $p(X_1 | Y) = p(X_2 | Y)$, Thus naive Bayes double counts the evidence.\n",
    "\n",
    "Using a conditional model is only possible when $X$ is observed. When some $X_i$ variables are unobserved, the generative model allow us to compute $p(Y | X_{evidence})$ by marginalizing over the unseen variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95fa15-1595-4db3-98d0-3e6340a176cd",
   "metadata": {},
   "source": [
    "**Logistic Regression** is stronger than **Naive Bayes** in practice because it make weaker assumptions. Therefore, if you have less data try Naive Bayes because it makes stronger assumptions, so there is no need with many data to figure out the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e2b4d-3fc1-43e8-8e7a-fef7abd26e3e",
   "metadata": {},
   "source": [
    "### Neural Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dce0b2-6498-45d6-9cb0-67ec9acb15a4",
   "metadata": {},
   "source": [
    "**None-linear dependence**: let $h(A,b,x) = f(Ax+b)$ be a non-linear transformation of the inputs (features).\n",
    "$$p_{Neural} (Y=1 | x;\\alpha,A,b) = \\sigma(\\alpha_0 + \\sum_{i=1}^h \\alpha_ih_i)$$\n",
    "- More Flexible\n",
    "- More Parameters: $A, b, \\alpha$\n",
    "- Can repeat multiple times to get a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d83d0-aa5c-43a5-aee1-26cd8248a8b6",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "  <img height=\"100%\" width=\"50%\" src=\"sources/M1_1_7.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a840971-892b-403a-9636-9476c4589bee",
   "metadata": {},
   "source": [
    "**Continuous Variables**\n",
    "If X is a continuous random variable, we can use *probability density function* $p_X: \\mathbb{R} \\rightarrow \\mathbb{R}^+$. Typically, consider parameterized densities:\n",
    "- Gaussian: $X \\sim N(\\mu,\\sigma)$ if $p_X(x) = \\frac{1}{\\sigma \\sqrt{2[\\pi}} e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$\n",
    "- Uniform: $X \\sim \\mu(a,b)$ if $p_X(x)=\\frac{1}{b-a} 1[a\\leq x\\leq b]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb34d7b1-b48c-484b-a9a8-e389c4504d53",
   "metadata": {},
   "source": [
    "If X is a continuous random vector, we can usually represent it using its **joint probability density function**.\n",
    "- Gaussian: if $p_X(x) = \\frac{1}{\\sqrt{(2\\pi})^n |\\sum|} exp(\\frac{-\\frac{1}{2}(x-\\mu)^T \\sum^{-1}(x-\\mu)})$\n",
    "\n",
    "Chain Rule, Bayes Rule still apply.\n",
    "$$p_{X,Y,Z}(x,y,z) = p_X(x)p_{Y|X}(y|x) p_{Z|\\{X,Y\\}}(z|x,y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edd491-2d73-44ae-8010-328d91229a4a",
   "metadata": {},
   "source": [
    "We can still use Bayesian Networks with continuous (and discrete) variables.\n",
    "\n",
    "For example: **Mixture of 2 Gaussians**: Bayes net $Z \\rightarrow X$ with factorization $p_{Z,X}(z,x) = p_Z(z)p_{X|Z}(x|z)$ and\n",
    "- $Z \\sim Bernoulli(p)$\n",
    "- $X|(Z=0) \\sim N(\\mu_0,\\sigma_0)$, $X|(Z=1)\\sim N(\\mu_0,\\sigma_0)$\n",
    "- The parameters are $p,\\mu_0,\\sigma_0,\\mu_1,\\sigma_1$\n",
    "  \n",
    "Bayes Net $Z \\rightarrow X$ with factorization  $p_{Z,X}(z,x) = p_Z(z)p_{X|Z}(x|z)$ and\n",
    "- $Z \\sim \\mu(a,b)$\n",
    "- $X|(Z=z) \\sim N(z,\\sigma)$\n",
    "- The parameters are $a,b,\\sigma$\n",
    "\n",
    "Variational Autoencoder: Bayes net $Z \\rightarrow X$ with factorization $p_{Z,X}(z,x) = p_Z(z)p_{X|Z}(x|z)$ and\n",
    "- $Z\\sim N(0,1)$\n",
    "- $X|(Z=z) \\sim N(\\mu_{\\theta}(z),e^{\\sigma_{\\theta}})$,where $\\mu_{\\theta}: \\mathbb{R} \\rightarrow \\mathbb{R}$ and $\\sigma_{\\phi}$ are neural networks with parameters (weights) $\\theta$,$\\phi$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4eaf47-8aeb-4221-9456-e93246d7f6fd",
   "metadata": {},
   "source": [
    "## Module 2 Autoregressive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f3848-454e-46ee-ac1f-48eb5866ec9d",
   "metadata": {},
   "source": [
    "### FVSBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d256c89-8b6a-4cc6-b73a-d473dc54f7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
